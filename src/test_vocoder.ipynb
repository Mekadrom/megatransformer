{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65bd4d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pytorch bin\n",
      "Loaded model from ../../megatransformer/runs/vocoder/test_0_0/checkpoint-78000/pytorch_model.bin\n",
      "Loaded vocoder from ../../megatransformer/runs/vocoder/test_0_0/checkpoint-78000/\n",
      "Vocoder parameters: 2,283,266\n",
      "Vocoder structure: Vocoder(\n",
      "  (input_proj): Conv1d(80, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (backbone): ModuleList(\n",
      "    (0-1): 2 x ConvNeXtBlock(\n",
      "      (dwconv): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (pwconv1): Linear(in_features=128, out_features=1024, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (pwconv2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    )\n",
      "    (2): FrequencyAttentionBlock(\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (proj_dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3-4): 2 x ConvNeXtBlock(\n",
      "      (dwconv): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (pwconv1): Linear(in_features=128, out_features=1024, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (pwconv2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    )\n",
      "    (5): FrequencyAttentionBlock(\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (proj_dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6-7): 2 x ConvNeXtBlock(\n",
      "      (dwconv): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (pwconv1): Linear(in_features=128, out_features=1024, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (pwconv2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    )\n",
      "    (8): ConvNeXtBlock(\n",
      "      (dwconv): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (pwconv1): Linear(in_features=128, out_features=1024, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (pwconv2): Linear(in_features=1024, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (mag_head_low): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (mag_head_high): Conv1d(64, 385, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (phase_head_low): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "    (1): Snake()\n",
      "    (2): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  )\n",
      "  (phase_head_high): Sequential(\n",
      "    (0): Snake()\n",
      "    (1): Conv1d(64, 385, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from model.audio.vocoder.vocoder import Vocoder\n",
    "from utils.audio_utils import SharedWindowBuffer\n",
    "\n",
    "\n",
    "def load_model(\n",
    "    model_cls,\n",
    "    config_name: str,\n",
    "    checkpoint_path: Optional[str] = None,\n",
    "    device: str = \"cuda\",\n",
    "    overrides: dict = {},\n",
    "    strict: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Load a model from a checkpoint.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_path: Path to checkpoint directory (containing model.safetensors or pytorch_model.bin)\n",
    "        config_name: Config name from the model class (e.g., \"small\", \"medium\")\n",
    "        device: Device to load the model on\n",
    "\n",
    "    Returns:\n",
    "        model in eval mode\n",
    "    \"\"\"\n",
    "    # Create model with same config\n",
    "    model = model_cls.from_config(config_name, **overrides)\n",
    "    model = model.to(device)\n",
    "\n",
    "    if checkpoint_path is None:\n",
    "        return model\n",
    "\n",
    "    # Try to load from safetensors first, then pytorch_model.bin\n",
    "    safetensors_path = os.path.join(checkpoint_path, \"model.safetensors\")\n",
    "    pytorch_path = os.path.join(checkpoint_path, \"pytorch_model.bin\")\n",
    "    if os.path.exists(safetensors_path):\n",
    "        from safetensors.torch import load_file\n",
    "        state_dict = load_file(safetensors_path)\n",
    "        model.load_state_dict(state_dict, strict=strict)\n",
    "        print(f\"Loaded model from {safetensors_path}\")\n",
    "    elif os.path.exists(pytorch_path):\n",
    "        print(f\"loading pytorch bin\")\n",
    "        state_dict = torch.load(pytorch_path, map_location=device, weights_only=True)\n",
    "        model.load_state_dict(state_dict, strict=strict)\n",
    "        print(f\"Loaded model from {pytorch_path}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No model checkpoint found at {checkpoint_path}. \"\n",
    "            f\"Expected model.safetensors or pytorch_model.bin\"\n",
    "        )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_vocoder(shared_window_buffer, vocoder_checkpoint_path, vocoder_config, is_wrapped: bool = False):\n",
    "    \"\"\"Lazily load vocoder on first use.\"\"\"\n",
    "    if vocoder_checkpoint_path is None:\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(vocoder_checkpoint_path):\n",
    "        print(f\"Vocoder checkpoint not found at {vocoder_checkpoint_path}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        if is_wrapped:\n",
    "            class VocoderWrapper(torch.nn.Module):\n",
    "                def __init__(self):\n",
    "                    super().__init__()\n",
    "                    self.vocoder: Optional[Vocoder] = None\n",
    "\n",
    "                @classmethod\n",
    "                def from_config(cls, config_name: str, shared_window_buffer: Optional[SharedWindowBuffer], **overrides) -> \"VocoderWrapper\":\n",
    "                    wrapper = cls()\n",
    "                    wrapper.vocoder = Vocoder.from_config(config_name, shared_window_buffer=shared_window_buffer, **overrides)\n",
    "                    return wrapper\n",
    "\n",
    "            vocoder = load_model(VocoderWrapper, vocoder_config, checkpoint_path=vocoder_checkpoint_path, overrides={\"shared_window_buffer\": shared_window_buffer}, strict=False).vocoder\n",
    "            vocoder.eval()\n",
    "        else:\n",
    "            vocoder = load_model(Vocoder, vocoder_config, checkpoint_path=vocoder_checkpoint_path, overrides={\"shared_window_buffer\": shared_window_buffer}, strict=False)\n",
    "            vocoder.eval()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load vocoder: {e}\")\n",
    "        raise e\n",
    "\n",
    "    print(f\"Loaded vocoder from {vocoder_checkpoint_path}\")\n",
    "    print(f\"Vocoder parameters: {sum(p.numel() for p in vocoder.parameters()):,}\")\n",
    "    print(f\"Vocoder structure: {vocoder}\")\n",
    "    return vocoder\n",
    "    \n",
    "shared_window_buffer = SharedWindowBuffer()\n",
    "vocoder = load_vocoder(shared_window_buffer, \"../../megatransformer/runs/vocoder/test_0_0/checkpoint-78000/\", \"tiny\", is_wrapped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dbfb6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[-1.8921e-02, -2.0605e-01,  4.4141e-01,  ..., -4.5312e-01,\n",
       "           6.6406e-01, -2.3828e-01],\n",
       "         [-2.6562e-01, -9.0942e-03, -1.8359e-01,  ..., -2.9883e-01,\n",
       "          -5.7373e-02,  4.4189e-02],\n",
       "         [-9.5215e-02, -1.1475e-02, -1.9238e-01,  ..., -1.2695e-01,\n",
       "          -1.2451e-01, -1.4551e-01],\n",
       "         ...,\n",
       "         [ 3.4961e-01,  1.1670e-01, -1.5234e-01,  ..., -5.5664e-02,\n",
       "           1.4941e-01, -1.2500e-01],\n",
       "         [ 3.1836e-01,  6.1646e-03,  3.8605e-03,  ...,  9.9609e-02,\n",
       "          -5.2979e-02,  3.6377e-02],\n",
       "         [ 2.4902e-01,  2.1582e-01,  1.3672e-01,  ...,  1.2891e-01,\n",
       "           2.2168e-01,  1.1426e-01]],\n",
       "\n",
       "        [[ 5.6641e-01,  5.1953e-01,  7.3047e-01,  ..., -1.5234e-01,\n",
       "          -4.2773e-01, -1.7090e-01],\n",
       "         [ 1.6992e-01,  9.3384e-03,  1.0059e-01,  ..., -2.2754e-01,\n",
       "          -1.6797e-01,  3.2959e-02],\n",
       "         [-3.9258e-01, -4.6484e-01, -4.2578e-01,  ..., -4.0820e-01,\n",
       "          -2.6953e-01, -3.3594e-01],\n",
       "         ...,\n",
       "         [ 2.1387e-01, -4.2419e-03, -3.2715e-02,  ...,  3.0859e-01,\n",
       "           6.1328e-01,  4.2773e-01],\n",
       "         [-1.1328e+00, -1.1016e+00, -1.4219e+00,  ..., -9.1406e-01,\n",
       "          -9.8828e-01, -9.7266e-01],\n",
       "         [ 2.4844e+00,  2.3594e+00,  2.3438e+00,  ...,  2.0000e+00,\n",
       "           1.7422e+00,  1.8359e+00]],\n",
       "\n",
       "        [[ 4.1748e-02,  1.4453e-01,  5.0000e-01,  ..., -4.4336e-01,\n",
       "          -3.9258e-01, -2.1680e-01],\n",
       "         [ 6.8054e-03, -5.2979e-02,  3.8477e-01,  ..., -3.3203e-01,\n",
       "          -2.5781e-01, -9.3750e-02],\n",
       "         [-1.8652e-01, -2.3730e-01, -5.4688e-01,  ..., -1.3867e-01,\n",
       "          -1.5430e-01, -1.5234e-01],\n",
       "         ...,\n",
       "         [-6.2012e-02, -1.4941e-01, -3.0859e-01,  ...,  3.3984e-01,\n",
       "           3.4375e-01,  3.7354e-02],\n",
       "         [ 2.9883e-01,  1.3867e-01, -3.6328e-01,  ...,  3.4375e-01,\n",
       "           7.3438e-01,  5.0781e-01],\n",
       "         [-4.1016e-01,  1.0205e-01,  8.9844e-01,  ...,  2.6172e-01,\n",
       "          -3.8477e-01, -5.5078e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.8311e-03, -9.8145e-02, -1.3867e-01,  ..., -8.0078e-02,\n",
       "           7.1289e-02, -5.5664e-02],\n",
       "         [-3.7109e-02,  1.4648e-01,  6.2012e-02,  ...,  2.0142e-03,\n",
       "           6.0059e-02,  1.5869e-02],\n",
       "         [ 5.9082e-02,  1.0547e-01,  7.0190e-03,  ...,  1.7090e-01,\n",
       "           8.6914e-02, -4.5654e-02],\n",
       "         ...,\n",
       "         [-2.3071e-02,  1.5625e-02, -3.1494e-02,  ...,  6.1035e-02,\n",
       "          -4.8340e-02, -7.5684e-02],\n",
       "         [-1.5259e-03,  7.7637e-02, -3.6621e-03,  ..., -1.5234e-01,\n",
       "           5.4688e-02,  2.6489e-02],\n",
       "         [ 7.4768e-03,  1.4453e-01,  1.4551e-01,  ...,  1.4160e-01,\n",
       "           1.3770e-01,  1.1292e-02]],\n",
       "\n",
       "        [[-6.7383e-02, -3.5352e-01,  2.1582e-01,  ..., -3.1250e-02,\n",
       "          -2.8564e-02, -9.2773e-02],\n",
       "         [-6.0059e-02,  3.2812e-01,  5.3223e-02,  ..., -2.4902e-02,\n",
       "           1.7578e-01,  1.9727e-01],\n",
       "         [ 2.5391e-01,  5.7129e-02,  4.0430e-01,  ...,  6.4453e-01,\n",
       "           2.1484e-01,  1.9922e-01],\n",
       "         ...,\n",
       "         [-5.4443e-02,  2.2949e-02, -2.7930e-01,  ...,  1.9824e-01,\n",
       "          -1.5747e-02,  5.6152e-02],\n",
       "         [-2.5513e-02,  2.7539e-01,  4.1016e-01,  ...,  9.2285e-02,\n",
       "           2.6172e-01,  2.7832e-02],\n",
       "         [ 2.6953e-01,  2.7539e-01, -9.6680e-02,  ...,  1.3367e-02,\n",
       "           2.2754e-01,  3.4180e-01]],\n",
       "\n",
       "        [[-8.4229e-03,  1.0315e-02, -9.1797e-02,  ...,  3.2471e-02,\n",
       "           7.9590e-02, -6.6895e-02],\n",
       "         [ 4.1260e-02,  8.8867e-02,  2.2363e-01,  ...,  7.6660e-02,\n",
       "           3.7354e-02,  2.4902e-02],\n",
       "         [ 1.0254e-01,  1.6699e-01,  8.1543e-02,  ...,  5.2002e-02,\n",
       "           3.8086e-02, -2.4170e-02],\n",
       "         ...,\n",
       "         [-1.0864e-02, -9.0942e-03,  7.8613e-02,  ...,  1.2500e-01,\n",
       "          -1.2451e-01,  2.5391e-02],\n",
       "         [ 1.6357e-02,  8.2520e-02,  5.4199e-02,  ..., -1.0498e-01,\n",
       "           1.3855e-02,  2.6855e-02],\n",
       "         [ 7.9102e-02,  4.5898e-02,  7.2266e-02,  ...,  5.2246e-02,\n",
       "           1.1133e-01,  3.6621e-02]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocoder.mag_head_low.weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
