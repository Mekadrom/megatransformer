{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vocoder Hyperparameter Optimization\n",
        "\n",
        "Multi-objective Bayesian optimization using Optuna's ask-and-tell interface.\n",
        "\n",
        "**Objectives (all minimized):** SC, LogMag, Waveform L1, Mel Spec L1\n",
        "\n",
        "**Hyperparameters:**\n",
        "- Learning rate: 1e-4 to 1e-2 (log scale)\n",
        "- Batch size: 32, 64, or 128\n",
        "- Weight decay: 1e-6 to 1e-2 (log scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run once: pip install optuna optuna-dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-29 00:17:55,400] A new study created in RDB with name: vocoder_v14\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Study 'vocoder_v14' loaded/created with 0 existing trials\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "DB_PATH = \"sqlite:///vocoder_study.db\"\n",
        "STUDY_NAME = \"vocoder_v14\"\n",
        "\n",
        "study = optuna.create_study(\n",
        "    study_name=STUDY_NAME,\n",
        "    storage=DB_PATH,\n",
        "    directions=[\"minimize\"],  # composite score incorporating reconstruction losses and run viability\n",
        "    load_if_exists=True\n",
        ")\n",
        "\n",
        "print(f\"Study '{STUDY_NAME}' loaded/created with {len(study.trials)} existing trials\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Historical Trials\n",
        "\n",
        "Edit the list below with your existing trial data, then run the cell once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 2 historical trials\n"
          ]
        }
      ],
      "source": [
        "historical_trials = [\n",
        "    # {\"params\": {\"lr\": 1e-4, \"batch_size\": 32, \"weight_decay\": 1e-5}, \"values\": [SC, MagLoss, WaveL1, MelRecon, ComplexSTFT, GANLoss, FMLoss, DiscLoss]},\n",
        "]\n",
        "\n",
        "if historical_trials:\n",
        "    for trial_data in historical_trials:\n",
        "        study.enqueue_trial(trial_data[\"params\"])\n",
        "        trial = study.ask()\n",
        "        if \"values\" in trial_data:\n",
        "            study.tell(trial, trial_data[\"values\"])\n",
        "        else:\n",
        "            study.tell(trial, state=optuna.trial.TrialState.FAIL)\n",
        "    print(f\"Loaded {len(historical_trials)} historical trials\")\n",
        "else:\n",
        "    print(\"No historical trials to load (list is empty)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get Next Suggestion\n",
        "\n",
        "Run this cell to get parameters for your next training run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--learning_rate 0.0007105249615645953 --weight_decay 0.00012551252892016514 --sc_loss_weight 0.991773834269867 --mag_loss_weight 1.8910770223024658 --wave_l1_loss_weight 0.1930552779587998 --mel_recon_loss_weight 0.28391407602588115 --complex_stft_loss_weight 1.6401797894429857 --gan_loss_weight 0.5324566225883319 --feature_matching_loss_weight 2.5544041807691356 --discriminator_lr 0.0009555942265828252\n",
            "{\"params\": {\"lr\": 0.0007105249615645953, \"batch_size\": 64, \"weight_decay\": 0.00012551252892016514, \"sc_loss_weight\": 0.991773834269867, \"mag_loss_weight\": 1.8910770223024658, \"wave_l1_loss_weight\": 0.1930552779587998, \"mel_recon_loss_weight\": 0.28391407602588115, \"complex_stft_loss_weight\": 1.6401797894429857, \"gan_loss_weight\": 0.5324566225883319, \"feature_matching_loss_weight\": 2.5544041807691356, \"discriminator_lr\": 0.0009555942265828252, \"gan_start_step\": 0.4946179393972899}}\n"
          ]
        }
      ],
      "source": [
        "trial = study.ask()\n",
        "\n",
        "# Define parameter spaces (only needed for generating new suggestions)\n",
        "batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
        "base_lr = trial.suggest_float(\"base_lr\", 1e-5, 1e-3, log=True)\n",
        "lr = base_lr * (batch_size / 32.0)\n",
        "discriminator_lr_ratio = trial.suggest_float(\"discriminator_lr_ratio\", 0.5, 2.0)\n",
        "discriminator_lr = lr * discriminator_lr_ratio\n",
        "gan_start_step = trial.suggest_float(\"gan_start_step\", 0.3, 0.7)\n",
        "weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
        "\n",
        "sc_raw = trial.suggest_float(\"sc_raw\", 0.1, 2.0)\n",
        "mag_raw = trial.suggest_float(\"mag_raw\", 0.1, 5.0)\n",
        "wave_raw = trial.suggest_float(\"wave_raw\", 0.1, 2.0)\n",
        "mel_raw = trial.suggest_float(\"mel_raw\", 0.1, 2.0)\n",
        "complex_raw = trial.suggest_float(\"complex_raw\", 0.1, 3.0)\n",
        "\n",
        "total_raw = sc_raw + mag_raw + wave_raw + mel_raw + complex_raw\n",
        "target_total = 5.0\n",
        "\n",
        "sc_loss_weight = sc_raw / total_raw * target_total\n",
        "mag_loss_weight = mag_raw / total_raw * target_total\n",
        "wave_l1_loss_weight = wave_raw / total_raw * target_total\n",
        "mel_recon_loss_weight = mel_raw / total_raw * target_total\n",
        "complex_stft_loss_weight = complex_raw / total_raw * target_total\n",
        "\n",
        "gan_loss_weight = trial.suggest_float(\"gan_loss_weight\", 0.1, 1.0)\n",
        "fm_ratio = trial.suggest_float(\"fm_ratio\", 1.0, 5.0)\n",
        "feature_matching_loss_weight = gan_loss_weight * fm_ratio\n",
        "\n",
        "print(f\"--learning_rate {lr} --weight_decay {weight_decay} --sc_loss_weight {sc_loss_weight} --mag_loss_weight {mag_loss_weight} --wave_l1_loss_weight {wave_l1_loss_weight} --mel_recon_loss_weight {mel_recon_loss_weight} --complex_stft_loss_weight {complex_stft_loss_weight} --gan_loss_weight {gan_loss_weight} --feature_matching_loss_weight {feature_matching_loss_weight} --discriminator_lr {discriminator_lr}\")\n",
        "print('{\"params\": {\"lr\": '+str(lr)+', \"batch_size\": '+str(batch_size)+', \"weight_decay\": '+str(weight_decay)+', \"sc_loss_weight\": '+str(sc_loss_weight)+', \"mag_loss_weight\": '+str(mag_loss_weight)+', \"wave_l1_loss_weight\": '+str(wave_l1_loss_weight)+', \"mel_recon_loss_weight\": '+str(mel_recon_loss_weight)+', \"complex_stft_loss_weight\": '+str(complex_stft_loss_weight)+ ', \"gan_loss_weight\": '+str(gan_loss_weight)+', \"feature_matching_loss_weight\": '+str(feature_matching_loss_weight)+', \"discriminator_lr\": '+str(discriminator_lr)+', \"gan_start_step\": '+str(gan_start_step)+'}}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_steps: 51562.5 --gan_start_step 25503\n"
          ]
        }
      ],
      "source": [
        "# convert gan metric to step count\n",
        "total_examples = 1_100_000\n",
        "num_epochs = 3\n",
        "total_steps = (total_examples / float(batch_size)) * num_epochs\n",
        "gan_start_step_i = int(gan_start_step * total_steps)\n",
        "print(f\"total_steps: {total_steps} --gan_start_step {gan_start_step_i}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Result Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial Score: 11.359550138181817\n"
          ]
        }
      ],
      "source": [
        "def compute_trial_score(min_loss, steps_completed, total_steps):\n",
        "    progress = steps_completed / total_steps\n",
        "    # Penalty for dying early: ranges from 0 (finished) to some max (died immediately)\n",
        "    early_death_penalty = (1.0 - progress) * min_loss  # Scale penalty by loss magnitude\n",
        "    return min_loss + early_death_penalty\n",
        "\n",
        "# Fill these in with your results\n",
        "sc_loss = 0.8789       # Spectral Convergence\n",
        "logmag_loss = 2.875   # Log Magnitude\n",
        "wave_l1 = 0.01202       # Waveform L1\n",
        "mel_l1 = 3.016        # Mel Spectrogram L1\n",
        "complex_stft_loss = 0.1232  # Complex STFT Loss\n",
        "steps_completed = 36600  # e.g., 8000\n",
        "run_failed = False # if the run failed/crashed\n",
        "\n",
        "trial_score = compute_trial_score(min_loss=sc_loss+logmag_loss+wave_l1+mel_l1+complex_stft_loss, steps_completed=steps_completed, total_steps=total_steps)\n",
        "print(f\"Trial Score: {trial_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Record Results\n",
        "\n",
        "After training completes, fill in your 4 loss values and run this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial #0 marked as FAILED\n"
          ]
        }
      ],
      "source": [
        "# Record the result\n",
        "if run_failed:\n",
        "    study.tell(trial, state=optuna.trial.TrialState.FAIL)\n",
        "    print(f\"Trial #{trial.number} marked as FAILED\")\n",
        "elif None in [sc_loss, logmag_loss, wave_l1, mel_l1, complex_stft_loss]:\n",
        "    print(\"ERROR: Fill in all 5 loss values (or set run_failed=True)\")\n",
        "else:\n",
        "    study.tell(trial, [trial_score])\n",
        "    print(f\"Trial #{trial.number} recorded!\")\n",
        "    print(f\"  SC: {sc_loss}, LogMag: {logmag_loss}, Wave L1: {wave_l1}, Mel L1: {mel_l1}\")\n",
        "    print(', \"values\": ['+str(sc_loss)+', '+str(logmag_loss)+', '+str(wave_l1)+', '+str(mel_l1)+']')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Total trials: {len(study.trials)}\")\n",
        "print(f\"Completed: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\")\n",
        "print(f\"Failed: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}\")\n",
        "print()\n",
        "\n",
        "print(\"Pareto-optimal trials:\")\n",
        "print(\"=\"*80)\n",
        "for t in study.best_trials:\n",
        "    print(f\"Trial #{t.number}\")\n",
        "    print(f\"  Params: lr={t.params['lr']:.6f}, batch={t.params['batch_size']}, wd={t.params['weight_decay']:.6f}\")\n",
        "    print(f\"  Losses: SC={t.values[0]:.4f}, LogMag={t.values[1]:.4f}, WaveL1={t.values[2]:.4f}, MelL1={t.values[3]:.4f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## All Trials Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FrozenTrial(number=0, state=<TrialState.COMPLETE: 1>, values=[18.440459689696965], datetime_start=datetime.datetime(2025, 11, 28, 22, 0, 13, 566849), datetime_complete=datetime.datetime(2025, 11, 28, 22, 0, 13, 577776), params={}, user_attrs={}, system_attrs={'fixed_params': {'lr': 0.0004827238320533371, 'batch_size': 32, 'weight_decay': 0.007709498399240456, 'sc_loss_weight': 0.7477651161998835, 'mag_loss_weight': 2.8307514883247005, 'wave_l1_loss_weight': 0.062224622626292095, 'mel_recon_loss_weight': 0.8897692533857661, 'complex_stft_loss_weight': 0.4694895194633577, 'gan_loss_weight': 0.5322976549045951, 'feature_matching_loss_weight': 1.8543398400790423, 'discriminator_lr': 0.00044621946542211467, 'gan_start_step': 0.40622545454545456}}, intermediate_values={}, distributions={}, trial_id=17, value=None)\n",
            "FrozenTrial(number=1, state=<TrialState.COMPLETE: 1>, values=[11.359550138181817], datetime_start=datetime.datetime(2025, 11, 28, 22, 0, 13, 595058), datetime_complete=datetime.datetime(2025, 11, 28, 22, 0, 13, 600353), params={}, user_attrs={}, system_attrs={'fixed_params': {'lr': 0.00018346389742578256, 'batch_size': 32, 'weight_decay': 0.0001534769740561332, 'sc_loss_weight': 0.8724319318230576, 'mag_loss_weight': 0.909418107539184, 'wave_l1_loss_weight': 1.354003112965936, 'mel_recon_loss_weight': 0.5752325293116073, 'complex_stft_loss_weight': 1.2889143183602148, 'gan_loss_weight': 0.6470822024825159, 'feature_matching_loss_weight': 0.9118955145962234, 'discriminator_lr': 0.00032449197716355254, 'gan_start_step': 0.5440039771703308}}, intermediate_values={}, distributions={}, trial_id=18, value=None)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trial</th>\n",
              "      <th>lr</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>COMPOSITE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>32</td>\n",
              "      <td>0.007709</td>\n",
              "      <td>18.44046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>32</td>\n",
              "      <td>0.000153</td>\n",
              "      <td>11.35955</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   trial        lr  batch_size  weight_decay  COMPOSITE\n",
              "0      0  0.000483          32      0.007709   18.44046\n",
              "1      1  0.000183          32      0.000153   11.35955"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "rows = []\n",
        "for t in study.trials:\n",
        "    if t.state == optuna.trial.TrialState.COMPLETE:\n",
        "        print(t)\n",
        "        params = t.params if len(t.params.keys()) > 0 else t.system_attrs[\"fixed_params\"]\n",
        "        rows.append({\n",
        "            \"trial\": t.number,\n",
        "            \"lr\": params.get(\"lr\"),\n",
        "            \"batch_size\": params.get(\"batch_size\"),\n",
        "            \"weight_decay\": params.get(\"weight_decay\"),\n",
        "            \"COMPOSITE\": t.values[0],\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Launch Dashboard\n",
        "\n",
        "Run this in a terminal (not in the notebook):\n",
        "```bash\n",
        "optuna-dashboard sqlite:///vocoder_study.db\n",
        "```\n",
        "\n",
        "Then open http://localhost:8080 in your browser."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
